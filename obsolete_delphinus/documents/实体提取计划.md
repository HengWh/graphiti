背景：
开始一个项目，目的是实现基于自然语言的、结合上下文的搜索功能。
覆盖场景如下：
场景一：精准回忆文件
用户请求： “小王，帮我找下上周李明发我的那份关于‘盘古项目’的PPT。”
“妙豚豚”工作流：
情景大脑 (CG) 启动： 在“坚果云IM”中，筛选出时间范围=“上周”，参与人=“小王”和“李明”的所有ConversationSegment（对话片段）。
语义大脑 (KG) 介入： 解析查询中的实体“盘古项目”和“PPT”。它知道“盘古项目”是一个Project实体，PPT是一种Document类型。
双脑融合： 系统寻找既满足情景大脑筛选条件，又在内容上（或通过显式MENTIONS关系）与Project:盘古项目和Document.type:PPT这两个语义实体强相关的ConversationSegment。
呈现结果： “找到了。这是李明在上周四下午发给您的盘古项目周报.pptx，这是当时的聊天记录摘要：[...]”


我负责使用开源的graphiti图数据库，记录并查询数据。 (项目地址: https://github.com/getzep/graphiti)
我准备分两大步完成，一 IM对话预处理，完成实体提取与关系提取。 二 存入graphiti图数据库，并查询
其中第一步比较难，但是必须执行。


执行：
针对于实体提取，我可以调用LLM模型，自定义promt来完成。 除此之外，我本地还有已知的公司通讯录，其中有名称，邮箱。本地处理+LLM模型等各种方式，都可以来帮助完成实体提取。 我需要用完善的测试用例及结果，来验证实体提取的效果。 最终应该输出一个稳定可靠的python脚本，能完成实体提取。

提取的实体应该只有以下项：
Person: 员工
Project: 项目
Document: 文档
Task: 任务
Meeting: 会议
ConversationSegment: 对话片段（IM内容的核心载体）


测试先行，参考 场景一，先帮我生成5段，约500字的公司内部IM对话记录。 这些IM对话，需要是黄金数据，且能覆盖大部分的回忆文件的场景。