### **项目备忘录：企业IM实体提取系统的设计与评估**

**备忘录目的:** 本文档旨在全面记录一个旨在从企业内部即时通讯（IM）对话中提取结构化信息的项目。它详细描述了项目的目标、方法论、已创建的关键资产、当前状态以及后续步骤，以便项目可以无缝地继续进行。

**1. 项目核心目标 (The "Why")**

我们的最终目标是构建一个可靠的自动化系统，能够**从非结构化的内部IM对话文本中，精准地提取出对业务有价值的实体信息**，并将其转换为**标准化的JSON格式**。这些结构化数据将用于支持下游应用，如：
*   自动化任务跟踪与指派。
*   项目知识库的自动构建。
*   关键决策和文件存档。
*   业务数据分析。

**2. 已执行的方法论与流程 (The "How")**

我们采用了一种系统化、分步迭代的方法来确保系统的质量和可评估性：

*   **第一步：定义实体与Schema**
    *   我们确定了需要提取的5种核心实体类型：`Person`, `Project`, `Document`, `Task`, `Meeting`。
    *   我们为`Document`和`Code`实体定义了详细的嵌套`attributes`，以捕获更丰富的元数据（如：`title`, `version`, `format`等）。
    *   我们引入了一个关键的`context`字段，用于捕获实体在原文中的上下文，以便于人工审核和理解提取依据。

*   **第二步：构建“黄金标准”数据集 (Ground Truth)**
    *   我们创建了一系列模拟真实场景的对话样本（`conversations/dialogue_*.txt`）。
    *   针对每一个对话样本，我们**人工审核并手动创建了**一份完全符合预定义Schema的JSON文件作为“基准真相”（`ground_truths/ground_truth_*.json`）。
    *   这些Ground Truth文件是评估模型性能的唯一标准，我们对其准确性非常有信心。

*   **第三步：设计高精度Prompt**
    *   我们精心设计了一个综合性的Prompt (`prompts/extract_entity.py`)，其核心特点包括：
        *   **明确的角色扮演**（"你是一个顶级的实体提取AI..."）。
        *   **详尽的实体定义和示例**，为模型提供清晰的指导。
        *   **严格的JSON输出格式约束**，并提供了一个“Few-shot”示例来强化格式要求。
        *   **刻意排除了ID字段的生成** (`conversation_id`, `entity_id`)，因为这些应由外部程序控制，以降低模型的复杂性和错误率。

*   **第四步：搭建并执行自动化测试框架**
    *   我们编写了一个全面的Python测试脚本（`test_entity_extraction.py`），并成功执行了初步测试。

**3. 已创建的关键资产清单 (The "What")**

*   **`/conversations`**: 包含所有待测试的原始对话文本文件 (`.txt`)。
*   **`/ground_truths`**: 包含与每个对话一一对应、人工验证过的JSON基准文件。
*   **`/reports`**: 用于存放所有生成的测试报告。
*   **`test_entity_extraction.py`**: 核心自动化测试脚本，具备以下功能：
    *   使用`python-dotenv`安全加载API密钥。
    *   连接到Google Gemini 2.5 Pro模型。
    *   实现了两种可配置的测试模式：**"LLM Only"** 和 **"LLM + Regex"**。
    *   循环处理所有对话，调用LLM进行实体提取。
    *   使用`deepdiff`库将模型输出与Ground Truth进行深度、精确的比较。
    *   使用`rich`库在控制台生成美观、清晰的测试总结报告。
    *   为失败的测试用例自动生成详细的、逐项对比的Markdown报告。
    *   将包含所有细节（输入、输出、差异）的详细测试结果保存到`/reports`目录下的JSON文件中。
*   **`requirements.txt`**: 定义了项目的所有Python依赖库。
*   **`.env`**: 配置文件模板，用于存储API密钥。

**4. 当前项目状态 (Where We Are)**

**我们已经成功搭建并初步验证了整个自动化测试与评估框架。**

项目已经从“纯框架搭建”阶段进入“**测试驱动的迭代优化**”阶段。我们已经使用`test_entity_extraction.py`脚本，针对第一个对话样本（`dialogue_1`）成功完成了一次完整的端到端测试。

测试结果表明：
*   整个流程（读取数据 -> 调用LLM -> 对比结果 -> 生成报告）是通畅的。
*   `LLM Only` 模式能够运行，并生成了可分析的结果。
*   测试脚本能够准确地发现预测结果与Ground Truth之间的差异，并生成了详细的 `.md` 和 `.json` 报告。

框架已经准备就绪，可以用于进行更大规模的测试和系统化的性能评估。

**5. 下一步行动计划 (Next Steps)**

1.  **执行全面测试与评估**:
    *   **目标**: 对所有对话样本进行测试，获取全面的基线性能数据。
    *   **操作**:
        *   移除 `test_entity_extraction.py` 主循环中的 `break` 语句，以对 `conversations/` 目录下的所有文件进行测试。
        *   取消对 "LLM + Regex" 测试模式的注释，同时评估两种模式的性能，以便对比分析纯LLM与混合策略的优劣。

2.  **系统性分析与迭代优化**:
    *   **目标**: 基于全面的测试结果，识别模型的系统性弱点并进行针对性优化。
    *   **操作**:
        *   **共性问题分析**: 仔细审查 `/reports` 目录下的所有失败报告，寻找反复出现的错误模式。例如：模型是否总是遗漏 `Meeting` 实体？是否对 `Person` 的识别存在偏差？
        *   **Prompt 优化**: 根据发现的共性问题，迭代优化 `prompts/extract_entity.py` 中的指令、示例或实体定义。
        *   **正则规则调优**: 分析 "LLM + Regex" 模式的结果。确认正则规则（当前为提取文件名）是否有效提升了召回率，同时有没有引入新的错误（精确率下降）。根据需要调整 `extract_entities_with_regex` 函数。
        *   **实体归一化**: `get_entity_key` 函数已为 `Person` 实现了初步的归一化逻辑。这是一个关键的优化点，后续可以扩展到其他实体类型（如 `Project` 名称的变体），以提高比对的准确性。

3.  **代码重构与健壮性提升**:
    *   **目标**: 提升代码的可维护性和可扩展性。
    *   **操作**:
        *   **模块化**: 考虑将核心功能（如 `call_llm_api`, `extract_entities_with_regex`）拆分到独立的模块中（例如，创建一个 `delphinus/extraction/` 目录），使测试脚本更聚焦于测试流程本身。
        *   **配置化**: 将硬编码在代码中的模型名称 (`gemini-2.5-pro`)、API URL等提取到 `.env` 或一个专门的配置文件中，使其更易于管理和切换。

---
